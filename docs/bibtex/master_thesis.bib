Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Lewis1979,
abstract = {A simple and relatively efficient method for simulating one-dimensional and two-dimensional nonhomogeneous Poisson processes is presented. The method is applicable for any rate function and is based on controlled deletion of points in a Poisson process whose rate function dominates the given rate function. In its simplest implementation, the method obviates the need for numerical integration of the rate function, for ordering of points, and for generation of Poisson variates.},
author = {Lewis, P. A.W. and Shedler, G. S.},
doi = {10.1002/nav.3800260304},
file = {:home/gizem/Downloads/a059904.pdf:pdf},
issn = {00281441},
journal = {Naval research logistics quarterly},
number = {3},
pages = {403--413},
title = {{Simulation of Nonhomogeneous Poisson Processes By Thinning.}},
volume = {26},
year = {1979}
}
@article{Perkins2009a,
abstract = {Stochasticity pervades life at the cellular level. Cells receive stochastic signals, perform detection and transduction with stochastic biochemistry, and grow and die in stochastic environments. Here we review progress in going from the molecular details to the information-processing strategies cells use in their decision-making. Such strategies are fundamentally influenced by stochasticity. We argue that the cellular decision-making can only be probabilistic and occurs at three levels. First, cells must infer from noisy signals the probable current and anticipated future state of their environment. Second, they must weigh the costs and benefits of each potential response, given that future. Third, cells must decide in the presence of other, potentially competitive, decision-makers. In this context, we discuss cooperative responses where some individuals can appear to sacrifice for the common good. We believe that decision-making strategies will be conserved, with comparatively few strategies being implemented by different biochemical mechanisms in many organisms. Determining the strategy of a decision-making network provides a potentially powerful coarse-graining that links systems and evolutionary biology to understand biological design. {\textcopyright} 2009 EMBO and Macmillan Publishers Limited. All rights reserved.},
author = {Perkins, Theodore J. and Swain, Peter S.},
doi = {10.1038/msb.2009.83},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perkins, Swain - 2009 - Strategies for cellular decision-making.pdf:pdf},
issn = {17444292},
journal = {Molecular Systems Biology},
keywords = {Biochemical networks,Decision theory,Decision-making,Social evolution,Statistical inference},
number = {326},
pages = {1--15},
publisher = {Nature Publishing Group},
title = {{Strategies for cellular decision-making}},
url = {http://dx.doi.org/10.1038/msb.2009.83},
volume = {5},
year = {2009}
}
@book{Sutton2018,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
author = {Sutton, Richard S. and Barto, Andrew G.},
booktitle = {The MIT Press},
isbn = {9780262039246},
title = {{Reinforcement Learning, Second Edition: An Introduction - Complete Draft}},
year = {2018}
}
@article{Bowsher2014,
abstract = {The recognition that gene expression can be substantially stochastic poses the question of how cells respond to dynamic environments using biochemistry that itself fluctuates. The study of cellular decision-making aims to solve this puzzle by focusing on quantitative understanding of the variation seen across isogenic populations in response to extracellular change. This behaviour is complex, and a theoretical framework within which to embed experimental results is needed. Here we review current approaches, with an emphasis on information theory, sequential data processing, and optimality arguments. We conclude by highlighting some limitations of these techniques and the importance of connecting both theory and experiment to measures of fitness. {\textcopyright} 2014 Elsevier Ltd.},
author = {Bowsher, Clive G. and Swain, Peter S.},
doi = {10.1016/j.copbio.2014.04.010},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowsher, Swain - 2014 - Environmental sensing, information transfer, and cellular decision-making.pdf:pdf},
issn = {18790429},
journal = {Current Opinion in Biotechnology},
pages = {149--155},
publisher = {Elsevier Ltd},
title = {{Environmental sensing, information transfer, and cellular decision-making}},
url = {http://dx.doi.org/10.1016/j.copbio.2014.04.010},
volume = {28},
year = {2014}
}
@article{White1980,
abstract = {In this paper, it is shown that, if the expected cost-to-go functions generated by a suboptimal design for a partially observed, discrete-time, Markov decision problem with a specific state measurement quality are concave, then the suboptimal design has a desirable adaptivity characteristic relative to that state measurement quality. Optimal strategies are shown to possess this adaptivity characteristic, as does a suboptimal design presented in an example. {\textcopyright} 1980 Plenum Publishing Corporation.},
author = {White, C. C. and Harrington, D. P.},
doi = {10.1007/BF00934845},
file = {:home/gizem/Downloads/White-Harrington1980{\_}Article{\_}ApplicationOfJensenSInequality.pdf:pdf},
issn = {00223239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Jensen's inequality,Partially observed Markov decision problems,Radon-Nikodym derivative,adaptivity,information quality},
number = {1},
pages = {89--99},
title = {{Application of Jensen's inequality to adaptive suboptimal design}},
volume = {32},
year = {1980}
}
@article{Ogaata1981,
abstract = {A simple and efficient method of simulation is discussed for point processes that are specified by their conditional intensities. The method is based on the thinning algorithm which was introduced recently by Lewis and Shedler for the simulation of nonhomogeneous Poisson processes. Algorithms are given for past dependent point processes containing multivariate processes. The simulations are performed for some parametric conditional intensity functions, and the accuracy of the simulated data is demonstrated by the likelihood ratio test and the minimum Akaike information criterion (AIC) procedure. {\textcopyright} 1981 IEEE},
author = {Ogaata, Yosihiko},
doi = {10.1109/TIT.1981.1056305},
file = {:home/gizem/Downloads/0a3c2dcec939784ce208e0e7e7fda4be895c.pdf:pdf},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
number = {1},
pages = {23--31},
title = {{On Lewis' Simulation Method for Point Processes}},
volume = {27},
year = {1981}
}
@article{Kaelbling2011,
abstract = {The aim of this work is to analyze and compare several feature extraction methods for peptide classification that are based on the calculation of texture descriptors starting from a matrix representation of the peptide. This texture-based representation of the peptide is then used to train a support vector machine classifier. In our experiments, the best results are obtained using local binary patterns variants and the discrete cosine transform with selected coefficients. These results are better than those previously reported that employed texture descriptors for peptide representation. In addition, we perform experiments that combine standard approaches based on amino acid sequence. The experimental section reports several tests performed on a vaccine dataset for the prediction of peptides that bind human leukocyte antigens and on a human immunodeficiency virus (HIV-1). Experimental results confirm the usefulness of our novel descriptors. The matlab implementation of our approaches is available at http://bias.csr.unibo.it/nanni/TexturePeptide.zip . {\textcopyright} 2010 Springer-Verlag.},
author = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
doi = {10.1007/s00726-010-0654-8},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaelbling, Littman, Cassandra - 2011 - Planning and acting in partially observable stochastic domains.pdf:pdf},
issn = {09394451},
journal = {Artificial Intelligence},
keywords = {Discrete cosine transform,HIV-1 protease prediction,Locally binary patterns,Peptide classification,Support vector machine,Vaccine development},
number = {2},
pages = {443--451},
pmid = {20552381},
title = {{Planning and acting in partially observable stochastic domains}},
volume = {40},
year = {1998}
}
@article{Edward2019,
author = {Edward, Sondik},
file = {:home/gizem/Downloads/169635.pdf:pdf},
number = {2},
pages = {282--304},
title = {{The Optimal Control of Partially Observable Markov Processes Over the Infinite Horizon : Discounted Costs Author ( s ): Edward J . Sondik Published by : INFORMS Stable URL : https://www.jstor.org/stable/169635 REFERENCES Linked references are available on}},
volume = {26},
year = {2019}
}
@article{Perez-Ocon2000,
abstract = {A nonhomogeneous Markov process is applied for analysing a cohort of women with breast cancer that were submitted to surgery. The follow-up was scheduled every month. Three states are considered: no relapse, relapse and death. As relapse times change over time, we have extended previous approaches for a time-homogeneous model to a nonhomogeneous multistate process. The transition intensity functions among states are the hazard rate functions of different lognormal distributions; we therefore build the likelihood function for this model, estimate the parameters and compare the empirical and nonhomogeneous models in terms of the survival probability functions. The parameter estimation is done following the maximum likelihood method. The effect of treatments is incorporated as covariates by means of the lognormal hazard rate functions, following the proportional hazard model. Thus, we have a multistate model with multidimensional covariates. Survival functions for the different cohorts submitted to treatments are obtained and goodness-of-fit tests are performed.},
author = {P{\'{e}}rez-Oc{\'{o}}n, Rafael and Ruiz-Castro, J. Eloy and G{\'{a}}miz-P{\'{e}}rez, M. Luz},
doi = {10.1007/BF02595740},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/P{\'{e}}rez-Oc{\'{o}}n, Ruiz-Castro, G{\'{a}}miz-P{\'{e}}rez - 2000 - Markov models with Iognormal transition rates in the analysis of survival times.pdf:pdf},
issn = {11330686},
journal = {Test},
keywords = {Covariates,Lognormal distribution,Maximum-likelihood estimate,Nonhomogeneous Markov process,Survival data},
number = {2},
pages = {353--370},
title = {{Markov models with Iognormal transition rates in the analysis of survival times}},
volume = {9},
year = {2000}
}
@article{Paarporn2018a,
abstract = {Collective action dilemmas pervade the social and biological sciences - from human decision-making to bacterial quorum sensing. In these scenarios, individuals sense cues from the environment to adopt a suitable phenotype or change in behavior. However, when cues include signals from other individuals, then the appropriate behavior of each individual is linked. Here, we develop a framework to quantify the influence of information sharing on individual behavior in the context of two player coordination games. In this framework, the environment stochastically switches between two states, and the state determines which one of two actions players must coordinate on. Given a stochastically switching environment, we then consider two versions of the game that differ in the way players acquire information. In the first model, players independently sense private environmental cues, but do not communicate with each other. We find there are two types of strategies that emerge as Nash equilibria and fitness maximizers - players prefer to commit to one particular action when private information is poor, or prefer to employ phenotypic plasticity when it is good. The second model adds an additional layer of communication, where players share social cues as well. When the quality of social information is high, we find the socially optimal strategy is a novel “majority logic” strategy that bases decision-making on social cues. Our game-theoretic approach offers a principled way of investigating the role of communication in group decision-making under uncertain conditions.},
author = {Paarporn, Keith and Eksin, Ceyhun and Weitz, Joshua S.},
doi = {10.1016/j.jtbi.2018.06.022},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paarporn, Eksin, Weitz - 2018 - Information sharing for a coordination game in fluctuating environments.pdf:pdf},
issn = {10958541},
journal = {Journal of Theoretical Biology},
keywords = {Coordination,Game theory,Information sharing,Uncertain environments},
pages = {376--385},
title = {{Information sharing for a coordination game in fluctuating environments}},
volume = {454},
year = {2018}
}
@article{Gkigkitzis2013,
abstract = {Background: The aim of this report is to provide a mathematical model of the mechanism for making binary fate decisions about cell death or survival, during and after Photodynamic Therapy (PDT) treatment, and to supply the logical design for this decision mechanism as an application of rate distortion theory to the biochemical processing of information by the physical system of a cell. Methods. Based on system biology models of the molecular interactions involved in the PDT processes previously established, and regarding a cellular decision-making system as a noisy communication channel, we use rate distortion theory to design a time dependent Blahut-Arimoto algorithm where the input is a stimulus vector composed of the time dependent concentrations of three PDT related cell death signaling molecules and the output is a cell fate decision. The molecular concentrations are determined by a group of rate equations. The basic steps are: initialize the probability of the cell fate decision, compute the conditional probability distribution that minimizes the mutual information between input and output, compute the cell probability of cell fate decision that minimizes the mutual information and repeat the last two steps until the probabilities converge. Advance to the next discrete time point and repeat the process. Results: Based on the model from communication theory described in this work, and assuming that the activation of the death signal processing occurs when any of the molecular stimulants increases higher than a predefined threshold (50{\%} of the maximum concentrations), for 1800s of treatment, the cell undergoes necrosis within the first 30 minutes with probability range 90.0{\%}-99.99{\%} and in the case of repair/survival, it goes through apoptosis within 3-4 hours with probability range 90.00{\%}-99.00{\%}. Although, there is no experimental validation of the model at this moment, it reproduces some patterns of survival ratios of predicted experimental data. Conclusions: Analytical modeling based on cell death signaling molecules has been shown to be an independent and useful tool for prediction of cell surviving response to PDT. The model can be adjusted to provide important insights for cellular response to other treatments such as hyperthermia, and diseases such as neurodegeneration. {\textcopyright} 2013 Gkigkitzis; licensee BioMed Central Ltd.},
author = {Gkigkitzis, Ioannis},
doi = {10.1186/1755-8794-6-S3-S3},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gkigkitzis - 2013 - Theoretical aspects and modelling of cellular decision making, cell killing and information-processing in photodynam.pdf:pdf},
issn = {17558794},
journal = {BMC Medical Genomics},
number = {SUPPL. 3},
pages = {1--16},
title = {{Theoretical aspects and modelling of cellular decision making, cell killing and information-processing in photodynamic therapy of cancer}},
volume = {6},
year = {2013}
}
@article{Sawaki1978,
abstract = {In this paper we consider an optimal control problem for partially observable Markov decision processes with finite states, signals and actions OVE,r an infinite horizon. It is shown that there are €-optimal piecewise{\textperiodcentered}linear value functions and piecl{\~{}}wise-constant policies which are simple. Simple means that there are only finitely many pieces, each of which is defined on a convex polyhedral set. An algorithm based on the method of successive approximation is developed to compute €-optimal policy and €{\textperiodcentered}optimal cost. Furthermore, a special class of stationary policies, called finitely transient, will be considered. It will be shown that such policies have attractive properties which enable us to convert a partially observable Markov decision chain into a usual finite state Markov one.},
author = {Sawaki, Katsushige and Ichikawa, Akira},
doi = {10.15807/jorsj.21.1},
file = {:home/gizem/Downloads/Vol.21{\_}01{\_}001.pdf:pdf},
issn = {0453-4514},
journal = {Journal of the Operations Research Society of Japan},
number = {1},
pages = {1--16},
title = {{Optimal Control for Partially Observable Markov Decision Processes Over an Infinite Horizon}},
volume = {21},
year = {1978}
}
@article{Murphy2000,
abstract = {This paper, we assume all actions take one unit of discrete time at some (unspecied) time scale. If we allow actions to take variable lengths of time, we end up with a semi-Markov model; see e.g., SPS99.},
author = {Murphy, K P},
doi = {10.1007/BF02204836},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murphy - 2000 - A survey of POMDP solution techniques.pdf:pdf},
issn = {0885-6125, 1573-0565},
journal = {Environment},
keywords = {Unsorted Import},
number = {September},
pages = {X3},
title = {{A survey of POMDP solution techniques}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.257{\&}rep=rep1{\&}type=pdf{\%}5Cnpapers2://publication/uuid/B7753077-665C-4305-AC31-C37A7A71DAC9},
volume = {2},
year = {2000}
}
@article{Song2019a,
author = {Song, Dongli and Yang, Dawei and Powell, Charles A. and Wang, Xiangdong},
doi = {10.1007/s10565-019-09470-y},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2019 - Cell–cell communication old mystery and new opportunity.pdf:pdf},
issn = {15736822},
journal = {Cell Biology and Toxicology},
number = {2},
pages = {89--93},
publisher = {Cell Biology and Toxicology},
title = {{Cell–cell communication: old mystery and new opportunity}},
volume = {35},
year = {2019}
}
@article{Opper2009,
abstract = {Markov jump processes play an important role in a large number of application domains. However, realistic systems are analytically intractable and they have traditionally been analysed using simulation based techniques, which do not provide a framework for statistical inference. We propose a mean field approximation to perform posterior inference and parameter estimation. The approximation allows a practical solution to the inference problem, while still retaining a good degree of accuracy. We illustrate our approach on two biologically motivated systems.},
archivePrefix = {arXiv},
arxivId = {1905.05451},
author = {Opper, Manfred and Sanguinetti, Guido},
eprint = {1905.05451},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Opper, Sanguinetti - 2009 - Variational inference for Markov jump processes.pdf:pdf},
isbn = {160560352X},
journal = {Advances in Neural Information Processing Systems 20 - Proceedings of the 2007 Conference},
title = {{Variational inference for Markov jump processes}},
year = {2009}
}
@article{KAELBLING199899,
abstract = {In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.},
author = {Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
doi = {https://doi.org/10.1016/S0004-3702(98)00023-X},
issn = {0004-3702},
journal = {Artificial Intelligence},
keywords = {Partially observable Markov decision processes,Planning,Uncertainty},
number = {1},
pages = {99--134},
title = {{Planning and acting in partially observable stochastic domains}},
url = {http://www.sciencedirect.com/science/article/pii/S000437029800023X},
volume = {101},
year = {1998}
}
@article{Masuda2018,
abstract = {The Gillespie algorithm provides statistically exact methods for simulating stochastic dynamics modeled as interacting sequences of discrete events including systems of biochemical reactions or earthquake occurrences, networks of queuing processes or spiking neurons, and epidemic and opinion formation processes on social networks. Empirically, the inter-event times of various phenomena obey long-tailed distributions. The Gillespie algorithm and its variants either assume Poisson processes (i.e., exponentially distributed inter-event times), use particular functions for time courses of the event rate, or work for non-Poissonian renewal processes, including the case of long-tailed distributions of inter-event times, but at a high computational cost. In the present study, we propose an innovative Gillespie algorithm for renewal processes on the basis of the Laplace transform. The algorithm makes use of the fact that a class of point processes is represented as a mixture of Poisson processes with different event rates. The method is applicable to multivariate renewal processes whose survival function of inter-event times is completely monotone. It is an exact algorithm and works faster than a recently proposed Gillespie algorithm for general renewal processes, which is exact only in the limit of infinitely many processes. We also propose a method to generate sequences of event times with a tunable amount of positive correlation between inter-event times. We demonstrate our algorithm with exact simulations of epidemic processes on networks, finding that a realistic amount of positive correlation in inter-event times only slightly affects the epidemic dynamics.},
archivePrefix = {arXiv},
arxivId = {1601.01490},
author = {Masuda, Naoki and Rocha, Luis E.C.},
doi = {10.1137/16M1055876},
eprint = {1601.01490},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masuda, Rocha - 2018 - A gillespie algorithm for Non-Markovian stochastic processes.pdf:pdf},
issn = {00361445},
journal = {SIAM Review},
keywords = {Laplace transform,Network,Numerical simulation,Point process},
number = {1},
pages = {95--115},
title = {{A gillespie algorithm for Non-Markovian stochastic processes}},
volume = {60},
year = {2018}
}
@article{Kobayashi2010a,
abstract = {Decision making in a noisy and dynamically changing environment is a fundamental task for a cell. To choose appropriate decisions over time, a cell must be equipped with intracellular kinetics that can conduct dynamic and efficient decision making. By using the theory of sequential inference, I demonstrate that dynamic Bayesian decision making can be implemented by an intracellular kinetics with a dual positive feedback structure. I also show that the combination of linear instantaneous and nonlinear stationary sensitivities to the input dominantly contributes to decision making efficiency, and that the state-dependent sensitivity change further suppresses noisy response. The statistical principles underlying these two factors are further clarified to be a log-likelihood-dependent quantification of the input information and uncertainty-dependent sensitivity control. {\textcopyright} 2010 The American Physical Society.},
author = {Kobayashi, Tetsuya J.},
doi = {10.1103/PhysRevLett.104.228104},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kobayashi - 2010 - Implementation of dynamic bayesian decision making by intracellular kinetics.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {22},
pages = {1--4},
title = {{Implementation of dynamic bayesian decision making by intracellular kinetics}},
volume = {104},
year = {2010}
}
@article{Foerster2016,
abstract = {We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.},
archivePrefix = {arXiv},
arxivId = {1605.06676},
author = {Foerster, Jakob N. and Assael, Yannis M. and {De Freitas}, Nando and Whiteson, Shimon},
eprint = {1605.06676},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foerster et al. - 2016 - Learning to communicate with deep multi-agent reinforcement learning.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {2145--2153},
title = {{Learning to communicate with deep multi-agent reinforcement learning}},
year = {2016}
}
@article{Linzner2019,
abstract = {Continuous-time Bayesian Networks (CTBNs) represent a compact yet powerful framework for understanding multivariate time-series data. Given complete data, parameters and structure can be estimated efficiently in closed-form. However, if data is incomplete, the latent states of the CTBN have to be estimated by laboriously simulating the intractable dynamics of the assumed CTBN. This is a problem, especially for structure learning tasks, where this has to be done for each element of super-exponentially growing set of possible structures. In order to circumvent this notorious bottleneck, we develop a novel gradient-based approach to structure learning. Instead of sampling and scoring all possible structures individually, we assume the generator of the CTBN to be composed as a mixture of generators stemming from different structures. In this framework, structure learning can be performed via a gradient-based optimization of mixture weights. We combine this approach with a novel variational method that allows for the calculation of the marginal likelihood of a mixture in closed-form. We proof the scalability of our method by learning structures of previously inaccessible sizes from synthetic and real-world data.},
archivePrefix = {arXiv},
arxivId = {1909.04570},
author = {Linzner, Dominik and Schmidt, Michael and Koeppl, Heinz},
eprint = {1909.04570},
file = {:home/gizem/Downloads/8631-scalable-structure-learning-of-continuous-time-bayesian-networks-from-incomplete-data (1).pdf:pdf},
number = {NeurIPS},
pages = {1--11},
title = {{Scalable Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data}},
url = {http://arxiv.org/abs/1909.04570},
year = {2019}
}
@article{Studer2016,
abstract = {Continuous Time Bayesian Networks (CTBNs) provide a powerful means to model complex network dynamics. However, their inference is computationally demanding - especially if one considers incomplete and noisy time-series data. The latter gives rise to a joint state-And parameter estimation problem, which can only be solved numerically. Yet, finding the exact parameterization of the CTBN has often only secondary importance in practical scenarios. We therefore focus on the structure learning problem and present a way to analytically marginalize the Markov chain underlying the CTBN model with respect its parameters. Since the resulting stochastic process is parameter-free, its inference reduces to an optimal filtering problem. We solve the latter using an efficient parallel implementation of a sequential Monte Carlo scheme. Our framework enables CTBN inference to be applied to incomplete noisy time-series data frequently found in molecular biology and other disciplines.},
author = {Studer, Lukas and Paulev{\'{e}}, Lo{\"{i}}c and Zechner, Christoph and Reumann, Matthias and Mart{\'{i}}nez, Mar{\'{i}}a Rodr{\'{i}}guez and Koeppl, Heinz},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Studer et al. - 2016 - Marginalized continuous time Bayesian networks for network reconstruction from incomplete observations.pdf:pdf},
isbn = {9781577357605},
journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
keywords = {Continuous time Bayesian network,Graph reconstruction,Sequential monte carlo},
pages = {2051--2057},
title = {{Marginalized continuous time Bayesian networks for network reconstruction from incomplete observations}},
year = {2016}
}
@article{Blei2017a,
abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this article, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find a member of that family which is close to the target density. Closeness is measured by Kullback–Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this article is to catalyze statistical research on this class of algorithms. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1601.00670},
author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
doi = {10.1080/01621459.2017.1285773},
eprint = {1601.00670},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blei, Kucukelbir, McAuliffe - 2017 - Variational Inference A Review for Statisticians.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Algorithms,Computationally intensive methods,Statistical computing},
number = {518},
pages = {859--877},
title = {{Variational Inference: A Review for Statisticians}},
volume = {112},
year = {2017}
}
@article{Nodelman1995,
author = {Nodelman, Uri and Shelton, Christian R and Koller, Daphne},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - 1995 - Continuous Time Bayesian Networks.pdf:pdf},
title = {{Continuous Time Bayesian Networks}},
year = {1995}
}
@article{Doucet2009,
abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented.},
author = {Doucet, Arnaud and Johansen, A M},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doucet, Johansen - 2009 - A tutorial on particle filtering and smoothing Fifteen years later.pdf:pdf},
journal = {Handbook of Nonlinear Filtering},
number = {December},
pages = {4--6},
title = {{A tutorial on particle filtering and smoothing: Fifteen years later}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.772{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{Rizoiu2017,
abstract = {This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and the key concepts in point processes. We then introduce the Hawkes process, its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data - we show how to model retweet cascades using a Hawkes self-exciting process. We presents a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available as an online appendix},
archivePrefix = {arXiv},
arxivId = {arXiv:1708.06401v2},
author = {Rizoiu, Marian-Andrei and Lee, Young and Mishra, Swapnil},
doi = {10.1145/3122865.3122874},
eprint = {arXiv:1708.06401v2},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rizoiu, Lee, Mishra - 2017 - Hawkes processes for events in social media.pdf:pdf},
journal = {Frontiers of Multimedia Research},
pages = {191--218},
title = {{Hawkes processes for events in social media}},
year = {2017}
}
@article{El-Hay2008,
abstract = {A central task in many applications is reasoning about processes that change over continuous time. Continuous-Time Bayesian Networks is a general compact representation language for multi-component continuous-time processes. However, exact inference in such processes is exponential in the number of components, and thus infeasible for most models of interest. Here we develop a novel Gibbs sampling procedure for multi-component processes. This procedure iteratively samples a trajectory for one of the components given the remaining ones. We show how to perform exact sampling that adapts to the natural time scale of the sampled process. Moreover, we show that this sampling procedure naturally exploits the structure of the network to reduce the computational cost of each step. This procedure is the first that can provide asymptotically unbiased approximation in such processes.},
archivePrefix = {arXiv},
arxivId = {1206.3251},
author = {El-Hay, Tal and Friedman, Nir and Kupferman, Raz},
eprint = {1206.3251},
file = {:home/gizem/Downloads/1206.3251.pdf:pdf},
isbn = {0974903949},
journal = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, UAI 2008},
pages = {169--178},
title = {{Gibbs sampling in factorized continuous-time Markov processes}},
year = {2008}
}
@article{Carlo1904,
author = {Thrun, Sebastian},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carlo, Integral - 1904 - Monte Carlo积分方法 Monte Carlo积分.pdf:pdf},
keywords = {scanned to PDF by gnv64},
number = {10},
pages = {117--151},
title = {{Monte Carlo POMDPs}},
volume = {40},
year = {1904}
}
@article{Nodelman2014,
abstract = {Streaming data are relevant to finance, computer science, and engineering while they are becoming increasingly important to medicine and biology. Continuous time Bayesian network classifiers are designed for analyzing multivariate streaming data when time duration of event matters. Structural and parametric learning for the class of continuous time Bayesian network classifiers are considered in the case where complete data is available. Conditional log-likelihood scoring is developed for structural learning on continuous time Bayesian network classifiers. Performance of continuous time Bayesian network classifiers learned when combining conditional log-likelihood scoring and Bayesian parameter estimation are compared with that achieved by continuous time Bayesian network classifiers when learning is based on marginal log-likelihood scoring and to that achieved by dynamic Bayesian network classifiers. Classifiers are compared in terms of accuracy and computation time. Comparison is based on numerical experiments where synthetic and real data are used. Results show that conditional log-likelihood scoring combined with Bayesian parameter estimation outperforms marginal log-likelihood scoring. Conditional log-likelihood scoring becomes even more effective when the amount of available data is limited. Continuous time Bayesian network classifiers outperform in terms of computation time and accuracy dynamic Bayesian network on synthetic and real data sets. {\textcopyright} 2014 Elsevier Inc.},
author = {Nodelman, Uri and Shelton, Christian R. and Koller, Daphne},
doi = {10.1016/j.ijar.2014.05.005},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - 2014 - Learning continuous time Bayesian networks.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Continuous time Bayesian networks,Continuous time classification,Multivariate trajectory,Streaming data},
number = {8},
pages = {1728--1746},
title = {{Learning continuous time Bayesian networks}},
volume = {55},
year = {2014}
}
@article{Thurley2018,
abstract = {Cell-to-cell communication networks have critical roles in coordinating diverse organismal processes, such as tissue development or immune cell response. However, compared with intracellular signal transduction networks, the function and engineering principles of cell-to-cell communication networks are far less understood. Major complications include: cells are themselves regulated by complex intracellular signaling networks; individual cells are heterogeneous; and output of any one cell can recursively become an additional input signal to other cells. Here, we make use of a framework that treats intracellular signal transduction networks as “black boxes” with characterized input-to-output response relationships. We study simple cell-to-cell communication circuit motifs and find conditions that generate bimodal responses in time, as well as mechanisms for independently controlling synchronization and delay of cell-population responses. We apply our modeling approach to explain otherwise puzzling data on cytokine secretion onset times in T cells. Our approach can be used to predict communication network structure using experimentally accessible input-to-output measurements and without detailed knowledge of intermediate steps. Interacting cellular communities have critical roles in biological functions such as tissue development or immune responses. Cell-to-cell communication networks comprise both intra- and intercellular processes, making detailed mathematical models intractable. Here, we develop a scalable framework for modeling extra-cellular communication networks that treats intracellular signal transduction networks as “black boxes” with characterized input-to-output response relationships. We discover that a range of dynamic cell-population behaviors, including cellular synchronization, delays, and bimodal responses, can emerge from simple cell-to-cell communication networks.},
author = {Thurley, Kevin and Wu, Lani F. and Altschuler, Steven J.},
doi = {10.1016/j.cels.2018.01.016},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thurley, Wu, Altschuler - 2018 - Modeling Cell-to-Cell Communication Networks Using Response-Time Distributions.pdf:pdf},
issn = {24054720},
journal = {Cell Systems},
keywords = {cell-to-cell communication,cytokine signals,first-passage time,response-time modeling},
number = {3},
pages = {355--367.e5},
publisher = {Elsevier},
title = {{Modeling Cell-to-Cell Communication Networks Using Response-Time Distributions}},
url = {http://dx.doi.org/10.1016/j.cels.2018.01.016},
volume = {6},
year = {2018}
}
@article{Blei,
author = {Blei, David M},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blei - Unknown - Variational-Inference-I.Pdf.pdf:pdf},
pages = {1--12},
title = {{Variational-Inference-I.Pdf}}
}
@article{Gillespie1976,
abstract = {An exact method is presented for numerically calculating, within the framework of the stochastic formulation of chemical kinetics, the time evolution of any spatially homogeneous mixture of molecular species which interreact through a specified set of coupled chemical reaction channels. The method is a compact, computer-oriented, Monte Carlo simulation procedure. It should be particularly useful for modeling the transient behavior of well-mixed gas-phase systems in which many molecular species participate in many highly coupled chemical reactions. For "ordinary" chemical systems in which fluctuations and correlations play no significant role, the method stands as an alternative to the traditional procedure of numerically solving the deterministic reaction rate equations. For nonlinear systems near chemical instabilities, where fluctuations and correlations may invalidate the deterministic equations, the method constitutes an efficient way of numerically examining the predictions of the stochastic master equation. Although fully equivalent to the spatially homogeneous master equation, the numerical simulation algorithm presented here is more directly based on a newly defined entity called "the reaction probability density function." The purpose of this article is to describe the mechanics of the simulation algorithm, and to establish in a rigorous, a priori manner its physical and mathematical validity; numerical applications to specific chemical systems will be presented in subsequent publications. {\textcopyright} 1976.},
author = {Gillespie, Daniel T.},
doi = {10.1016/0021-9991(76)90041-3},
file = {:home/gizem/Downloads/gillespie{\_}general{\_}method.pdf:pdf},
issn = {10902716},
journal = {Journal of Computational Physics},
number = {4},
pages = {403--434},
title = {{A general method for numerically simulating the stochastic time evolution of coupled chemical reactions}},
volume = {22},
year = {1976}
}
@article{Godsill2019,
author = {Godsill, Simon},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Godsill - 2019 - PARTICLE FILTERING THE FIRST 25 YEARS AND BEYOND Simon Godsill Signal Processing and Communications ( SigProC ) Labora.pdf:pdf},
isbn = {9781538646588},
pages = {7760--7764},
title = {{PARTICLE FILTERING: THE FIRST 25 YEARS AND BEYOND}},
year = {2019}
}
@article{article,
author = {Huang, Lirong and Paulev{\'{e}}, Lo{\"{i}}c and Zechner, Christoph and Unger, Michael and Hansen, Anders and Koeppl, Heinz},
doi = {10.6084/M9.FIGSHARE.3796026.V1},
title = {{Supporting Information for Reconstructing dynamic molecular states from single-cell time series}},
year = {2016}
}
@article{Cohn2010a,
abstract = {Continuous-time Bayesian networks is a natural structured representation language for multi- component stochastic processes that evolve continuously over time. Despite the compact represen- tation provided by this language, inference in such models is intractable even in relatively simple structured networks. We introduce a mean field variational approximation in which we use a prod- uct of inhomogeneous Markov processes to approximate a joint distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efficiently queried. Additionally, it provides a lower bound on the probability ofobservations, thus making it attractive for learning tasks. Here we describe the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations ofprocesses for which this approximation is suitable, and show applications to a large-scale real-world inference problem.},
author = {Cohn, Ido and El-Hay, Tal and Friedman, Nir and Kupferman, Raz},
file = {:home/gizem/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohn et al. - 2010 - Mean Field Variational Approximation for Continuous-Time Bayesian Networks.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {approximations,continuous time bayesian networks,continuous time markov processes,mean field approximation,variational},
pages = {2745--2783},
title = {{Mean Field Variational Approximation for Continuous-Time Bayesian Networks}},
url = {papers://04aadf0e-330a-4d63-bb92-2cd37bc2fdee/Paper/p648},
volume = {11},
year = {2010}
}
