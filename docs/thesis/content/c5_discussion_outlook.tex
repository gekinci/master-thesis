\chapter{Discussion}
\label{chap:5}
%Only because the agent can see information (obs model) doesn't mean it needs to use it (policy)
Motivated by the examples of multi-agent systems in nature, we modelled a communication between two parent nodes and an agent node combining CTBN and POMDP frameworks. While the parent nodes emit messages containing information about their states, the agent observes a translation of these messages from which it needs to form its belief state and make desicions. The nodes evolve continously in time as components of a CTBN, modelled as in \cref{sec:exp_ctbn_model}. Given that the messages of the parent nodes are unavailable to the agent, the interaction between parent nodes and the agent node is modelled as POMDP, as described in \cref{sec:exp_pomdp_model}.\\
The belief state is updated utilising two methods. The first one is exact update, discussed in \cref{par:bs_exact}, and assumes that the transition intensities of the parents $ \textbf{Q}_1 $ and $ \textbf{Q}_2 $ are available both for the agent and for the classifier. However, due to the fact that this would not present a realistic system, particle filtering with marginalized CTBN is introduced for as state estimator. Here, both the agent and the classifier was able to perform the belief state update, given Gamma-priors of $ \textbf{Q}_1 $ and $ \textbf{Q}_2 $.\\
The goal of this work is to infer the observation model from demonstrations. We consider this problem as classification between observation models and analyze the performance of the classifier in terms of the metrics AUROC and AUPR. The results are given in \autoref{fig:AUROC_class0} and \autoref{fig:AUPR_class0}, respectively. Using exact method to update the belief state, excellent performance is achieved for the classification task regarding AUROC metric. The stochasticity introduced by the marginal particle filtering results in a slightly lower performance, compared to exact update. Nevertheless, in both methods, as the number of samples increases, the metric approaces 1, which is expected in the case of unbiased classifier.\\
The results of the experiments with different levels of noise added to the observation model are given in \autoref{fig:AUROC_class0_error}. We assume the noise level is available to the agent, and the likelihoods of noise free observation models are considered for classification. Thus, the noisy model parameters are not estimated. The performance decreases as the noise introduced to the true observation model increases. These results confirm the expectations, as the noise leads to less reliable observations for the agent. On the other hand, with the increasing number of trajectories the metric converges to 1, showing the robustness.\\
An important limitation to the inference task is the equivalence classes as introduced in \cref{sec:eq_classes}. The set of observation models can be divided into 10 equivalence classes such that the likelihoods of a sample trajectory $ S^{[0,T]} $ given any observation model within one class are equal. This clearly limits the classifiers ability to determine the true model. Due to this limitation, set of observation models is reduced to 10 observation model, each one representing an equivalence class. These observation models are given in \cref{ap:obs_set_exp}. Consequently, the result which states that the true observation model is $ \psi_i $ is equivalent to that the true observation model belongs to $ \text{i}^{\text{th}} $ equivalence class. As shown with examples in \cref{ap:eq_classes}, there are two reason to this equivalence. The first reason can be specified as the equivalent effect of observation models on the belief state, which is inherent to the observation model structure. The second reason is that the different belief states might lead to the same behaviour. This case intuitively can be explained by the fact that the agent may not need to use all the information it has for decision making. This information loss limits the ability to infer what the agent has observed from its actions.\\

\chapter{Outlook}
\label{chap:6}
The first step in the future of this work is to eliminate the equivalence classes to be able to classify every observation model. This problem to a certain extent can be mitigated by joint inference of observation model and policy. The joint inference could be performed as a joint classification problem, where the combination of discrete values of these parameters are treated as classes. This is only feasible by defining appropriate constraints on the policy such that, as for the case of observation models in this work, the policy space is countable.\\ 
Another exiciting direction is to solve the policy optimization problem, instead of assuming that the optimal policy is given. By doing so, it would be feasible to utilise the classification method for observation model described in this work, in real-world data, providing insights in the interactions of agents and environments.\\
Foerster \textit{et al.} \cite{Foerster2016}
Multi-agent problem
